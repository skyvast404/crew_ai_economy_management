"""Agent äººç¾¤æ¨¡æ‹Ÿç ”ç©¶å¹³å° - Agent Crowd Simulation Platform

A Streamlit app that uses crewAI agents to simulate multi-agent crowd interactions.
Supports comparing the same topic under multiple leadership styles.
"""

import logging
import os
import threading
import time
from dataclasses import dataclass, field
from urllib.error import HTTPError, URLError
from urllib.request import Request, urlopen

import streamlit as st
from dotenv import load_dotenv

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from crewai import Crew
from crewai.events.event_bus import crewai_event_bus
from crewai.events.types.agent_events import (
    AgentExecutionCompletedEvent,
    AgentExecutionStartedEvent,
)
from crewai.events.types.task_events import TaskCompletedEvent, TaskStartedEvent

from lib_custom.crew_builder import CrewBuilder, build_comparison_crew
from lib_custom.leadership_styles import LEADERSHIP_STYLES, apply_style_to_roles
from lib_custom.llm_config import create_openrouter_llm, get_available_llms
from lib_custom.role_repository import RoleRepository


# ---------------------------------------------------------------------------
# Environment validation
# ---------------------------------------------------------------------------

def validate_api_endpoint() -> tuple[bool, str]:
    """Validate that the API endpoint is reachable.

    Returns:
        (is_valid, error_message)
    """
    base_url = os.getenv("OPENAI_BASE_URL", "")
    api_key = os.getenv("OPENAI_API_KEY", "")
    model_name = os.getenv("OPENAI_MODEL_NAME", "")

    if not api_key:
        return False, "âŒ OPENAI_API_KEY æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶"

    if not base_url:
        return False, "âŒ OPENAI_BASE_URL æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶"

    # Log model configuration for debugging
    if model_name:
        logger.info(f"Using model: {model_name}")
        if "gemini" in model_name.lower() and "127.0.0.1" not in base_url:
            logger.warning(
                f"Model '{model_name}' appears to be Gemini but URL is not local proxy. "
                "Ensure your proxy correctly translates OpenAI API to Gemini."
            )

    # Check if it's a local proxy
    if "127.0.0.1" in base_url or "localhost" in base_url:
        try:
            # Use an authenticated OpenAI-compatible endpoint to validate both connectivity and auth.
            test_url = base_url.rstrip("/") + "/models"
            req = Request(
                test_url,
                headers={
                    "Authorization": f"Bearer {api_key}",
                },
            )
            with urlopen(req, timeout=5) as response:
                response.read()
            return True, ""
        except HTTPError as e:
            if e.code == 401:
                return (
                    False,
                    f"âŒ æœ¬åœ°ä»£ç†é‰´æƒå¤±è´¥ (401 Unauthorized): {base_url}\n"
                    "è¯·æ£€æŸ¥ OPENAI_API_KEY æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ä»£ç†æ˜¯å¦éœ€è¦ä¸åŒçš„å¯†é’¥æ ¼å¼ã€‚",
                )
            if e.code == 403:
                return (
                    False,
                    f"âŒ æœ¬åœ°ä»£ç†æ— æƒé™è®¿é—® (403 Forbidden): {base_url}\n"
                    "è¯·æ£€æŸ¥ API Key æƒé™æˆ–ä»£ç†è®¿é—®æ§åˆ¶é…ç½®ã€‚",
                )
            return (
                False,
                f"âŒ æœ¬åœ°ä»£ç†è¿”å› HTTP {e.code}: {base_url}\n"
                f"é”™è¯¯: {e.reason}",
            )
        except URLError as e:
            return False, f"âŒ æ— æ³•è¿æ¥åˆ°æœ¬åœ°ä»£ç†: {base_url}\nè¯·ç¡®ä¿ä»£ç†æœåŠ¡æ­£åœ¨è¿è¡Œ\né”™è¯¯: {e.reason}"
        except TimeoutError:
            return False, f"âŒ è¿æ¥è¶…æ—¶: {base_url}\nè¯·æ£€æŸ¥ä»£ç†æœåŠ¡æ˜¯å¦æ­£å¸¸"
        except Exception as e:
            return False, f"âŒ è¿æ¥é”™è¯¯: {str(e)}"

    # For remote endpoints, assume they're valid (will fail later with better error)
    return True, ""


# ---------------------------------------------------------------------------
# Message store: thread-safe shared state between crew thread and Streamlit
# ---------------------------------------------------------------------------

@dataclass
class ChatMessage:
    role: str
    content: str
    msg_type: str
    timestamp: float = field(default_factory=time.time)


class ChatMessageStore:
    """Thread-safe container for chat messages shared between threads."""

    def __init__(self):
        self._messages: list[ChatMessage] = []
        self._lock = threading.Lock()
        self._done = False
        self._error: str | None = None
        self._cancelled = False

    def add(self, msg: ChatMessage):
        with self._lock:
            self._messages = [*self._messages, msg]

    def get_all(self) -> list[ChatMessage]:
        with self._lock:
            return list(self._messages)

    def mark_done(self):
        with self._lock:
            self._done = True

    def mark_error(self, error: str):
        with self._lock:
            self._error = error
            self._done = True

    def mark_cancelled(self):
        with self._lock:
            self._cancelled = True
            self._done = True

    @property
    def done(self) -> bool:
        with self._lock:
            return self._done

    @property
    def error(self) -> str | None:
        with self._lock:
            return self._error

    @property
    def cancelled(self) -> bool:
        with self._lock:
            return self._cancelled


# ---------------------------------------------------------------------------
# Module-level active store pointer â€” handlers write here (registered once)
# ---------------------------------------------------------------------------

_active_store: ChatMessageStore | None = None


# ---------------------------------------------------------------------------
# Register event handlers ONCE at module level (singleton event bus)
# ---------------------------------------------------------------------------

@crewai_event_bus.on(AgentExecutionStartedEvent)
def _on_agent_started(source, event: AgentExecutionStartedEvent):
    store = _active_store
    if store is not None:
        _progress_info["live"] = f"{event.agent.role} å¼€å§‹å‘è¨€"
        _progress_info["last_update"] = str(time.time())
        store.add(ChatMessage(
            role=event.agent.role,
            content=f"*{event.agent.role} å¼€å§‹å‘è¨€...*",
            msg_type="started",
        ))


@crewai_event_bus.on(AgentExecutionCompletedEvent)
def _on_agent_completed(source, event: AgentExecutionCompletedEvent):
    store = _active_store
    if store is not None:
        _progress_info["live"] = f"{event.agent.role} å‘è¨€å®Œæˆ"
        _progress_info["last_update"] = str(time.time())
        store.add(ChatMessage(
            role=event.agent.role,
            content=event.output,
            msg_type="completed",
        ))


@crewai_event_bus.on(TaskStartedEvent)
def _on_task_started(source, event: TaskStartedEvent):
    store = _active_store
    if store is not None:
        desc = ""
        if event.task and hasattr(event.task, "description"):
            desc = event.task.description[:80]
        _progress_info["live"] = f"ä»»åŠ¡å¼€å§‹: {desc}" if desc else "ä»»åŠ¡å¼€å§‹"
        _progress_info["last_update"] = str(time.time())
        store.add(ChatMessage(
            role="system",
            content=f"ğŸ“‹ ä»»åŠ¡å¼€å§‹: {desc}...",
            msg_type="task_started",
        ))


@crewai_event_bus.on(TaskCompletedEvent)
def _on_task_completed(source, event: TaskCompletedEvent):
    store = _active_store
    if store is not None:
        _progress_info["live"] = "ä»»åŠ¡å®Œæˆ"
        _progress_info["last_update"] = str(time.time())
        store.add(ChatMessage(
            role="system",
            content="âœ… ä»»åŠ¡å®Œæˆ",
            msg_type="task_completed",
        ))


# ---------------------------------------------------------------------------
# Avatar mapping â€” built dynamically from role config
# ---------------------------------------------------------------------------

def get_role_avatars() -> dict[str, str]:
    """Build avatar mapping from current role configuration."""
    try:
        repo = RoleRepository()
        db = repo.load_roles()
        avatars = {role.role_name: role.avatar for role in db.roles}
        avatars["system"] = "âš™ï¸"
        avatars["è·¨é£æ ¼å¯¹æ¯”åˆ†æå¸ˆ"] = "ğŸ“Š"
        return avatars
    except Exception:
        return {"system": "âš™ï¸"}


# ---------------------------------------------------------------------------
# Background thread runner
# ---------------------------------------------------------------------------

def _render_results_tabs(
    style_stores: dict[str, ChatMessageStore],
    style_ids: list[str],
):
    """Render results in tabs â€” one per style + optional comparison tab."""
    sim_topic = st.session_state.sim_topic
    sim_rounds = st.session_state.sim_num_rounds

    tab_names = [LEADERSHIP_STYLES[sid].style_name for sid in style_ids]
    has_comparison = "__comparison__" in style_stores
    if has_comparison:
        tab_names.append("ğŸ“Š è·¨é£æ ¼å¯¹æ¯”åˆ†æ")

    tabs = st.tabs(tab_names)

    for i, sid in enumerate(style_ids):
        style = LEADERSHIP_STYLES[sid]
        store = style_stores[sid]
        messages = store.get_all()

        with tabs[i]:
            if store.cancelled:
                st.warning("âš ï¸ æ­¤æ¨¡æ‹Ÿå·²è¢«å–æ¶ˆ")
            elif store.error:
                st.error(f"æ¨¡æ‹Ÿå‡ºé”™: {store.error}")
            else:
                render_messages(messages)
                render_analyst(messages)

            md = format_messages_as_markdown(
                messages, sim_topic, sim_rounds, style_name=style.style_name,
            )
            st.download_button(
                f"ğŸ“¥ ä¸‹è½½ {style.style_name} è®°å½•",
                data=md,
                file_name=f"simulation_{sid}.md",
                mime="text/markdown",
                key=f"dl_{sid}",
            )

    if has_comparison:
        comp_store = style_stores["__comparison__"]
        comp_messages = comp_store.get_all()
        with tabs[-1]:
            if comp_store.error:
                st.error(f"å¯¹æ¯”åˆ†æå‡ºé”™: {comp_store.error}")
            else:
                for msg in comp_messages:
                    if msg.msg_type == "completed":
                        st.markdown(msg.content)

            comp_text = "\n\n".join(
                msg.content for msg in comp_messages if msg.msg_type == "completed"
            )
            st.download_button(
                "ğŸ“¥ ä¸‹è½½è·¨é£æ ¼å¯¹æ¯”åˆ†æ",
                data=comp_text,
                file_name="comparison_analysis.md",
                mime="text/markdown",
                key="dl_comparison",
            )


# ---------------------------------------------------------------------------
# Render chat messages in Streamlit
# ---------------------------------------------------------------------------

def get_conversation_role_names() -> set[str]:
    """Get current conversation role names from repository."""
    try:
        repo = RoleRepository()
        db = repo.load_roles()
        return {role.role_name for role in db.get_conversation_roles()}
    except Exception:
        return {"è€æ¿ (Boss)", "èµ„æ·±å‘˜å·¥ (Senior)", "æ–°äºº (Newbie)"}


def format_messages_as_markdown(
    messages: list[ChatMessage],
    topic: str,
    num_rounds: int,
    style_name: str = "",
) -> str:
    """Format finished messages into a Markdown document for export."""
    avatars = get_role_avatars()
    conversation_roles = get_conversation_role_names()

    header = f"# Agent äººç¾¤æ¨¡æ‹Ÿè®°å½• â€” {style_name}" if style_name else "# Agent äººç¾¤æ¨¡æ‹Ÿè®°å½•"
    lines = [header, f"\n## è¯é¢˜ï¼š{topic}", f"\nå¯¹è¯è½®æ•°ï¼š{num_rounds}", ""]

    num_conv_roles = len(conversation_roles) or 3
    current_round = 0
    msgs_in_round = 0
    analyst_content = ""

    for msg in messages:
        if msg.msg_type != "completed":
            continue
        if msg.role not in conversation_roles:
            if "åˆ†æ" in msg.role and msg.msg_type == "completed":
                analyst_content = msg.content
            continue
        if msgs_in_round % num_conv_roles == 0:
            current_round += 1
            lines.append(f"\n### ç¬¬ {current_round} è½®\n")
        msgs_in_round += 1
        avatar = avatars.get(msg.role, "")
        lines.append(f"**{avatar} {msg.role}:**\n")
        lines.append(f"{msg.content}\n")

    if analyst_content:
        lines.append("\n---\n")
        lines.append("### åˆ†ææ€»ç»“\n")
        lines.append(analyst_content)

    return "\n".join(lines)


def render_messages(messages: list[ChatMessage]):
    """Render conversation messages (excludes analyst output)."""
    avatars = get_role_avatars()
    for msg in messages:
        if msg.msg_type == "started":
            continue
        if "åˆ†æ" in msg.role:
            continue
        avatar = avatars.get(msg.role, "ğŸ’¬")
        if msg.role == "system":
            st.caption(msg.content)
        else:
            with st.chat_message(msg.role, avatar=avatar):
                st.markdown(f"**{msg.role}**")
                st.write(msg.content)


def render_analyst(messages: list[ChatMessage]):
    """Render the analyst output in a separate expander."""
    for msg in messages:
        if "åˆ†æ" in msg.role and msg.msg_type == "completed":
            with st.expander("ğŸ“Š ç¾¤ä½“äº’åŠ¨åˆ†æ", expanded=False):
                st.markdown(msg.content)
            return


def extract_conversation_text(messages: list[ChatMessage]) -> str:
    """Extract completed conversation messages as plain text."""
    parts = []
    for msg in messages:
        if msg.msg_type == "completed" and msg.role != "system":
            parts.append(f"[{msg.role}]: {msg.content}")
    return "\n\n".join(parts)


# ---------------------------------------------------------------------------
# Multi-style simulation runner (synchronous, called from background thread)
# ---------------------------------------------------------------------------

def run_multi_style_simulation(
    topic: str,
    num_rounds: int,
    selected_style_ids: list[str],
    style_stores: dict[str, ChatMessageStore],
    progress_callback,
    config: dict,
):
    """Run simulation for each selected style sequentially.

    Populates style_stores with messages for each style, then runs comparison.
    """
    global _active_store
    repo = RoleRepository()
    base_db = repo.load_roles()
    total_steps = len(selected_style_ids) + 1  # +1 for comparison
    style_conversations: dict[str, str] = {}

    for idx, style_id in enumerate(selected_style_ids):
        style = LEADERSHIP_STYLES[style_id]
        store = style_stores[style_id]

        # Check if cancelled before starting
        if store.cancelled:
            logger.info(f"Simulation cancelled before starting {style.style_name}")
            break

        styled_db = apply_style_to_roles(base_db, style)
        builder = CrewBuilder(styled_db, config)
        crew = builder.build_crew(topic, num_rounds)

        try:
            _active_store = store
            progress_callback(idx, total_steps, style.style_name)
            logger.info(f"Starting simulation for style: {style.style_name}")
            logger.info(f"Topic: {topic}, Rounds: {num_rounds}")

            # Run crew with timeout monitoring
            start_time = time.time()
            crew.kickoff()
            elapsed = time.time() - start_time

            logger.info(f"Simulation completed for {style.style_name} in {elapsed:.1f}s")
            store.mark_done()
        except Exception as e:
            error_msg = f"{type(e).__name__}: {str(e)}"
            logger.error(f"Simulation failed for {style.style_name}: {error_msg}")

            # Attempt fallback with OpenRouter
            fallback_llm = create_openrouter_llm()
            if fallback_llm is not None:
                logger.info(f"Retrying {style.style_name} with OpenRouter fallback")
                _llm_route_info["active_provider"] = "openrouter"
                store.add(ChatMessage(
                    role="system",
                    content="âš ï¸ ä¸»æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œæ­£åœ¨åˆ‡æ¢åˆ° OpenRouter å¤‡é€‰æ¨¡å‹...",
                    msg_type="task_started",
                ))
                try:
                    fallback_builder = CrewBuilder(styled_db, config, llm=fallback_llm)
                    fallback_crew = fallback_builder.build_crew(topic, num_rounds)
                    start_time = time.time()
                    fallback_crew.kickoff()
                    elapsed = time.time() - start_time
                    logger.info(f"Fallback completed for {style.style_name} in {elapsed:.1f}s")
                    store.add(ChatMessage(
                        role="system",
                        content="âœ… OpenRouter å¤‡é€‰æ¨¡å‹å®Œæˆæ¨¡æ‹Ÿ",
                        msg_type="task_completed",
                    ))
                    store.mark_done()
                except Exception as fallback_err:
                    fallback_msg = f"{type(fallback_err).__name__}: {str(fallback_err)}"
                    logger.error(f"Fallback also failed for {style.style_name}: {fallback_msg}")
                    store.mark_error(f"ä¸»æ¨¡å‹: {error_msg}\nOpenRouter: {fallback_msg}")
            else:
                store.mark_error(error_msg)
        finally:
            _active_store = None

        style_conversations[style.style_name] = extract_conversation_text(
            store.get_all()
        )

    # Run cross-style comparison if multiple styles selected
    if len(selected_style_ids) > 1:
        comparison_store = style_stores.get("__comparison__")
        if comparison_store is not None:
            try:
                _active_store = comparison_store
                progress_callback(
                    len(selected_style_ids), total_steps, "è·¨é£æ ¼å¯¹æ¯”åˆ†æ"
                )
                logger.info("Starting cross-style comparison analysis")
                comparison_crew = build_comparison_crew(topic, style_conversations)

                start_time = time.time()
                comparison_crew.kickoff()
                elapsed = time.time() - start_time

                logger.info(f"Comparison analysis completed in {elapsed:.1f}s")
                comparison_store.mark_done()
            except Exception as e:
                error_msg = f"{type(e).__name__}: {str(e)}"
                logger.error(f"Comparison analysis failed: {error_msg}")

                fallback_llm = create_openrouter_llm()
                if fallback_llm is not None:
                    logger.info("Retrying comparison with OpenRouter fallback")
                    _llm_route_info["active_provider"] = "openrouter"
                    comparison_store.add(ChatMessage(
                        role="system",
                        content="âš ï¸ ä¸»æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œæ­£åœ¨åˆ‡æ¢åˆ° OpenRouter å¤‡é€‰æ¨¡å‹...",
                        msg_type="task_started",
                    ))
                    try:
                        fallback_crew = build_comparison_crew(
                            topic, style_conversations, llm=fallback_llm,
                        )
                        start_time = time.time()
                        fallback_crew.kickoff()
                        elapsed = time.time() - start_time
                        logger.info(f"Fallback comparison completed in {elapsed:.1f}s")
                        comparison_store.mark_done()
                    except Exception as fallback_err:
                        fallback_msg = f"{type(fallback_err).__name__}: {str(fallback_err)}"
                        logger.error(f"Fallback comparison also failed: {fallback_msg}")
                        comparison_store.mark_error(f"ä¸»æ¨¡å‹: {error_msg}\nOpenRouter: {fallback_msg}")
                else:
                    comparison_store.mark_error(error_msg)
            finally:
                _active_store = None


# ---------------------------------------------------------------------------
# Background thread wrapper for multi-style simulation
# ---------------------------------------------------------------------------

_progress_info: dict[str, str] = {
    "step": "0",
    "total": "1",
    "label": "å‡†å¤‡ä¸­...",
    "live": "ç­‰å¾…ä»»åŠ¡å¯åŠ¨",
}
_llm_route_info: dict[str, str] = {"active_provider": "primary"}


def _run_in_thread(topic, num_rounds, selected_style_ids, style_stores, config):
    """Background thread entry point for multi-style simulation."""

    def progress_callback(step, total, label):
        _progress_info["step"] = str(step + 1)
        _progress_info["total"] = str(total)
        _progress_info["label"] = label
        _progress_info["last_update"] = str(time.time())

    try:
        run_multi_style_simulation(
            topic, num_rounds, selected_style_ids, style_stores, progress_callback, config
        )
    finally:
        _progress_info["done"] = "true"


def _format_llm_route_label() -> str:
    """Return a human-readable current LLM route label."""
    provider = _llm_route_info.get("active_provider", "primary")
    if provider == "openrouter":
        return "OpenRouter å¤‡é€‰æ¨¡å‹"
    return "ä¸»æ¨¡å‹æ¥å£"


# ---------------------------------------------------------------------------
# Streamlit UI
# ---------------------------------------------------------------------------

def main():
    st.set_page_config(
        page_title="Agent äººç¾¤æ¨¡æ‹Ÿç ”ç©¶",
        page_icon="ğŸ”¬",
        layout="wide",
    )

    st.title("ğŸ”¬ Agent äººç¾¤æ¨¡æ‹Ÿç ”ç©¶")
    st.caption("åŸºäº LLM å¤šæ™ºèƒ½ä½“çš„ç¾¤ä½“è¡Œä¸ºæ¨¡æ‹Ÿ â€” é¢†å¯¼é£æ ¼å¯¹æ¯”åˆ†æ")

    # -- Sidebar --
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        topic = st.text_input(
            "ä¼šè®®è¯é¢˜",
            value="é¡¹ç›®å»¶æœŸäº†ï¼Œè°æ¥èƒŒé”…ï¼Ÿ",
            help="è¾“å…¥ä¸€ä¸ªæ¨¡æ‹Ÿåœºæ™¯è¯é¢˜",
        )
        num_rounds = st.slider(
            "å¯¹è¯è½®æ•°", min_value=1, max_value=10, value=3,
            help="æ¯è½®è§’è‰²å„å‘è¨€ä¸€æ¬¡ï¼Œè½®æ•°è¶Šå¤šå‰§æƒ…è¶Šä¸°å¯Œ",
        )

        with st.expander("ğŸ”§ é«˜çº§è®¾ç½®", expanded=False):
            agent_timeout = st.slider(
                "Agentè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰",
                min_value=30,
                max_value=300,
                value=120,
                step=30,
                help="å•ä¸ªAgentçš„æœ€å¤§æ‰§è¡Œæ—¶é—´ï¼Œè¶…æ—¶åä¼šç»ˆæ­¢",
            )
            max_iterations = st.slider(
                "æœ€å¤§è¿­ä»£æ¬¡æ•°",
                min_value=1,
                max_value=10,
                value=5,
                help="é˜²æ­¢Agenté™·å…¥æ— é™å¾ªç¯",
            )
            context_window = st.slider(
                "ä¸Šä¸‹æ–‡çª—å£ï¼ˆä»»åŠ¡æ•°ï¼‰",
                min_value=2,
                max_value=12,
                value=4,
                step=2,
                help="æ¯ä¸ªAgentèƒ½çœ‹åˆ°çš„å†å²ä»»åŠ¡æ•°é‡ï¼Œè¶Šå¤§æ¶ˆè€—è¶Šå¤štoken",
            )

        st.divider()

        # Model status display
        st.subheader("æ¨¡å‹é…ç½®")
        available_llms = get_available_llms()
        primary_model = os.getenv("OPENAI_MODEL_NAME", "æœªé…ç½®")
        primary_base_url = os.getenv("OPENAI_BASE_URL", "æœªé…ç½®")
        openrouter_model = os.getenv("OPENROUTER_MODEL_NAME", "")
        openrouter_key = os.getenv("OPENROUTER_API_KEY", "")
        openrouter_in_available = any(label == "OpenRouter" for label, _ in available_llms)

        st.caption(f"å½“å‰ä½¿ç”¨: **{_format_llm_route_label()}**")
        st.caption(f"ä¸»æ¥å£: `{primary_base_url}`")
        st.caption(f"ä¸»æ¨¡å‹: **{primary_model}**")
        if openrouter_key and openrouter_model and openrouter_in_available:
            st.caption("å¤‡é€‰æ¥å£: `https://openrouter.ai/api/v1`")
            st.caption(f"å¤‡é€‰æ¨¡å‹: **OpenRouter/{openrouter_model}** âœ…")
        elif openrouter_key and openrouter_model:
            st.caption(f"å¤‡é€‰æ¨¡å‹: **OpenRouter/{openrouter_model}** âš ï¸ å·²é…ç½®ä½†å½“å‰ç¯å¢ƒä¸å¯ç”¨")
        else:
            st.caption("å¤‡é€‰æ¨¡å‹: æœªé…ç½® âŒ")
        if len(available_llms) == 0:
            st.warning("âš ï¸ æ— å¯ç”¨æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ .env é…ç½®")

        st.divider()
        st.subheader("é¢†å¯¼é£æ ¼é€‰æ‹©")
        style_options = {
            sid: s.style_name for sid, s in LEADERSHIP_STYLES.items()
        }
        selected_styles = st.multiselect(
            "é€‰æ‹©è¦å¯¹æ¯”çš„é¢†å¯¼é£æ ¼ï¼ˆè‡³å°‘1ä¸ªï¼‰",
            options=list(style_options.keys()),
            default=list(style_options.keys()),
            format_func=lambda sid: f"{style_options[sid]}",
        )

        # Show style descriptions
        for sid in selected_styles:
            style = LEADERSHIP_STYLES[sid]
            st.caption(f"**{style.style_name}**: {style.description}")

        start_btn = st.button(
            "ğŸš€ å¼€å§‹æ¨¡æ‹Ÿ",
            type="primary",
            use_container_width=True,
            disabled=len(selected_styles) == 0,
        )

        st.divider()
        st.subheader("è§’è‰²ä»‹ç»")
        avatars = get_role_avatars()
        for role_name, avatar in avatars.items():
            if role_name not in ("system", "è·¨é£æ ¼å¯¹æ¯”åˆ†æå¸ˆ"):
                st.write(f"{avatar} **{role_name}**")

    # -- Initialize session state --
    if "style_stores" not in st.session_state:
        st.session_state.style_stores = {}
    if "running" not in st.session_state:
        st.session_state.running = False
    if "sim_topic" not in st.session_state:
        st.session_state.sim_topic = ""
    if "sim_num_rounds" not in st.session_state:
        st.session_state.sim_num_rounds = 3
    if "selected_style_ids" not in st.session_state:
        st.session_state.selected_style_ids = []
    if "agent_timeout" not in st.session_state:
        st.session_state.agent_timeout = 120
    if "max_iterations" not in st.session_state:
        st.session_state.max_iterations = 5
    if "context_window" not in st.session_state:
        st.session_state.context_window = 4

    # -- Handle start button --
    if start_btn and not st.session_state.running and selected_styles:
        # Validate API endpoint before starting
        is_valid, error_msg = validate_api_endpoint()
        if not is_valid:
            st.error(error_msg)
            st.info("ğŸ’¡ æç¤ºï¼šå¦‚æœä½¿ç”¨æœ¬åœ°ä»£ç†ï¼Œè¯·ç¡®ä¿ä»£ç†æœåŠ¡æ­£åœ¨è¿è¡Œ")
            st.stop()

        stores: dict[str, ChatMessageStore] = {}
        for sid in selected_styles:
            stores[sid] = ChatMessageStore()
        if len(selected_styles) > 1:
            stores["__comparison__"] = ChatMessageStore()

        st.session_state.style_stores = stores
        st.session_state.running = True
        st.session_state.sim_topic = topic
        st.session_state.sim_num_rounds = num_rounds
        st.session_state.selected_style_ids = list(selected_styles)
        st.session_state.agent_timeout = agent_timeout
        st.session_state.max_iterations = max_iterations
        st.session_state.context_window = context_window
        st.session_state.sim_started_at = time.time()

        _progress_info.clear()
        total_steps = len(selected_styles) + (1 if len(selected_styles) > 1 else 0)
        _progress_info["step"] = "0"
        _progress_info["total"] = str(max(total_steps, 1))
        _progress_info["label"] = "åˆå§‹åŒ–ä»»åŠ¡"
        _progress_info["live"] = "ç­‰å¾…ç¬¬ä¸€ä¸ªè§’è‰²å¼€å§‹"
        _progress_info["last_update"] = str(time.time())
        _llm_route_info["active_provider"] = "primary"

        config = {
            "agent_timeout": agent_timeout,
            "max_iterations": max_iterations,
            "context_window": context_window,
        }

        thread = threading.Thread(
            target=_run_in_thread,
            args=(topic, num_rounds, list(selected_styles), stores, config),
            daemon=True,
        )
        thread.start()

    # -- Main area: render based on state --
    style_stores = st.session_state.style_stores
    style_ids = st.session_state.selected_style_ids

    if st.session_state.running and style_stores:
        # Check if all stores are done
        all_done = all(
            store.done for sid, store in style_stores.items()
            if sid != "__comparison__"
        )
        comparison_store = style_stores.get("__comparison__")
        comparison_done = comparison_store.done if comparison_store else True

        if not (all_done and comparison_done):
            label = _progress_info.get("label", "å‡†å¤‡ä¸­...")
            step = int(_progress_info.get("step", "0") or "0")
            total = max(int(_progress_info.get("total", "1") or "1"), 1)
            live = _progress_info.get("live", "ç­‰å¾…ä»»åŠ¡å¯åŠ¨")
            started_at = st.session_state.get("sim_started_at", time.time())
            elapsed = int(time.time() - started_at)
            progress_ratio = min(max(step / total, 0.0), 1.0)
            col1, col2 = st.columns([3, 1])
            with col1:
                st.info(f"ğŸ”„ æ¨¡æ‹Ÿè¿›è¡Œä¸­ â€” {label}")
                st.progress(progress_ratio, text=f"é˜¶æ®µè¿›åº¦: {step}/{total}")
                st.caption(f"å·²è¿è¡Œ: {elapsed}s | æœ€è¿‘åŠ¨ä½œ: {live}")
            with col2:
                if st.button("ğŸ›‘ å–æ¶ˆæ¨¡æ‹Ÿ", type="secondary", use_container_width=True):
                    # Mark all stores as cancelled
                    for store in style_stores.values():
                        store.mark_cancelled()
                    st.session_state.running = False
                    st.warning("âš ï¸ æ¨¡æ‹Ÿå·²å–æ¶ˆ")
                    st.rerun()
            time.sleep(1.5)
            st.rerun()

        # All done â€” stop polling
        st.session_state.running = False

        # Check if any were cancelled
        any_cancelled = any(store.cancelled for store in style_stores.values())
        if any_cancelled:
            st.warning("âš ï¸ æ¨¡æ‹Ÿå·²è¢«ç”¨æˆ·å–æ¶ˆ")
        else:
            st.success("âœ… æ‰€æœ‰é£æ ¼æ¨¡æ‹Ÿå®Œæˆï¼")

    if style_stores and not st.session_state.running:
        _render_results_tabs(style_stores, style_ids)

    elif not style_stores:
        st.info("ğŸ‘ˆ åœ¨å·¦ä¾§é€‰æ‹©é¢†å¯¼é£æ ¼å¹¶è¾“å…¥è¯é¢˜ï¼Œç‚¹å‡»ã€Œå¼€å§‹æ¨¡æ‹Ÿã€")


main()
