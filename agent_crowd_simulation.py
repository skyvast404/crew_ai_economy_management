"""Agent äººç¾¤æ¨¡æ‹Ÿç ”ç©¶å¹³å° - Agent Crowd Simulation Platform

A Streamlit app that uses crewAI agents to simulate multi-agent crowd interactions.
Supports comparing the same topic under multiple leadership styles.
"""

import logging
import os
import threading
import time
from urllib.error import HTTPError, URLError
from urllib.request import Request, urlopen

import streamlit as st
from dotenv import load_dotenv

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from crewai import Crew
from crewai.types.streaming import CrewStreamingOutput, StreamChunkType

from lib_custom.chat_store import ChatMessage, ChatMessageStore
from lib_custom.crew_builder import CrewBuilder, build_comparison_crew
from lib_custom.leadership_styles import LEADERSHIP_STYLES, apply_style_to_roles
from lib_custom.llm_config import create_primary_llm
from lib_custom.role_repository import RoleRepository
from lib_custom.runtime_state import STATE as RUNTIME_STATE
from lib_custom.runtime_state import ensure_event_handlers_registered


# ---------------------------------------------------------------------------
# Environment validation
# ---------------------------------------------------------------------------

def validate_api_endpoint() -> tuple[bool, str]:
    """Validate that the API endpoint is reachable.

    Returns:
        (is_valid, error_message)
    """
    base_url = os.getenv("OPENAI_BASE_URL", "")
    api_key = os.getenv("OPENAI_API_KEY", "")
    model_name = os.getenv("OPENAI_MODEL_NAME", "")

    if not api_key:
        return False, "âŒ OPENAI_API_KEY æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶"

    if not base_url:
        return False, "âŒ OPENAI_BASE_URL æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶"

    # Log model configuration for debugging
    if model_name:
        logger.info(f"Using model: {model_name}")

    # Health-check: validate connectivity and auth via /models endpoint
    is_local = "127.0.0.1" in base_url or "localhost" in base_url
    timeout = 5 if is_local else 10

    try:
        test_url = base_url.rstrip("/") + "/models"
        req = Request(
            test_url,
            headers={
                "Authorization": f"Bearer {api_key}",
            },
        )
        with urlopen(req, timeout=timeout) as response:
            response.read()
        return True, ""
    except HTTPError as e:
        if e.code == 401:
            return (
                False,
                f"âŒ API é‰´æƒå¤±è´¥ (401 Unauthorized): {base_url}\n"
                "è¯·æ£€æŸ¥ OPENAI_API_KEY æ˜¯å¦æ­£ç¡®ã€‚",
            )
        if e.code == 403:
            return (
                False,
                f"âŒ API æ— æƒé™è®¿é—® (403 Forbidden): {base_url}\n"
                "è¯·æ£€æŸ¥ API Key æƒé™é…ç½®ã€‚",
            )
        return (
            False,
            f"âŒ API è¿”å› HTTP {e.code}: {base_url}\n"
            f"é”™è¯¯: {e.reason}",
        )
    except URLError as e:
        return False, f"âŒ æ— æ³•è¿æ¥åˆ° API: {base_url}\né”™è¯¯: {e.reason}"
    except TimeoutError:
        return False, f"âŒ è¿æ¥è¶…æ—¶: {base_url}\nè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸"
    except Exception as e:
        return False, f"âŒ è¿æ¥é”™è¯¯: {str(e)}"


ensure_event_handlers_registered()


# ---------------------------------------------------------------------------
# Avatar mapping â€” built dynamically from role config
# ---------------------------------------------------------------------------

def get_role_avatars() -> dict[str, str]:
    """Build avatar mapping from current role configuration."""
    try:
        repo = RoleRepository()
        db = repo.load_roles()
        avatars = {role.role_name: role.avatar for role in db.roles}
        avatars["system"] = "âš™ï¸"
        avatars["è·¨é£æ ¼å¯¹æ¯”åˆ†æå¸ˆ"] = "ğŸ“Š"
        return avatars
    except Exception:
        return {"system": "âš™ï¸"}


# ---------------------------------------------------------------------------
# Background thread runner
# ---------------------------------------------------------------------------

def _render_results_tabs(
    style_stores: dict[str, ChatMessageStore],
    style_ids: list[str],
):
    """Render results in tabs â€” one per style + optional comparison tab."""
    sim_topic = st.session_state.sim_topic
    sim_rounds = st.session_state.sim_num_rounds

    tab_names = [LEADERSHIP_STYLES[sid].style_name for sid in style_ids]
    has_comparison = "__comparison__" in style_stores
    if has_comparison:
        tab_names.append("ğŸ“Š è·¨é£æ ¼å¯¹æ¯”åˆ†æ")

    tabs = st.tabs(tab_names)

    for i, sid in enumerate(style_ids):
        style = LEADERSHIP_STYLES[sid]
        store = style_stores[sid]
        messages = store.get_all()

        with tabs[i]:
            if store.cancelled:
                st.warning("âš ï¸ æ­¤æ¨¡æ‹Ÿå·²è¢«å–æ¶ˆ")
            elif store.error:
                st.error(f"æ¨¡æ‹Ÿå‡ºé”™: {store.error}")
            else:
                render_messages(messages)
                render_analyst(messages)

            md = format_messages_as_markdown(
                messages, sim_topic, sim_rounds, style_name=style.style_name,
            )
            st.download_button(
                f"ğŸ“¥ ä¸‹è½½ {style.style_name} è®°å½•",
                data=md,
                file_name=f"simulation_{sid}.md",
                mime="text/markdown",
                key=f"dl_{sid}",
            )

    if has_comparison:
        comp_store = style_stores["__comparison__"]
        comp_messages = comp_store.get_all()
        with tabs[-1]:
            if comp_store.error:
                st.error(f"å¯¹æ¯”åˆ†æå‡ºé”™: {comp_store.error}")
            else:
                for msg in comp_messages:
                    if msg.msg_type == "completed":
                        st.markdown(msg.content)

            comp_text = "\n\n".join(
                msg.content for msg in comp_messages if msg.msg_type == "completed"
            )
            st.download_button(
                "ğŸ“¥ ä¸‹è½½è·¨é£æ ¼å¯¹æ¯”åˆ†æ",
                data=comp_text,
                file_name="comparison_analysis.md",
                mime="text/markdown",
                key="dl_comparison",
            )


# ---------------------------------------------------------------------------
# Render chat messages in Streamlit
# ---------------------------------------------------------------------------

def get_conversation_role_names() -> set[str]:
    """Get current conversation role names from repository."""
    try:
        repo = RoleRepository()
        db = repo.load_roles()
        return {role.role_name for role in db.get_conversation_roles()}
    except Exception:
        return {"è€æ¿ (Boss)", "èµ„æ·±å‘˜å·¥ (Senior)", "æ–°äºº (Newbie)"}


def format_messages_as_markdown(
    messages: list[ChatMessage],
    topic: str,
    num_rounds: int,
    style_name: str = "",
) -> str:
    """Format finished messages into a Markdown document for export."""
    avatars = get_role_avatars()
    conversation_roles = get_conversation_role_names()

    header = f"# Agent äººç¾¤æ¨¡æ‹Ÿè®°å½• â€” {style_name}" if style_name else "# Agent äººç¾¤æ¨¡æ‹Ÿè®°å½•"
    lines = [header, f"\n## è¯é¢˜ï¼š{topic}", f"\nå¯¹è¯è½®æ•°ï¼š{num_rounds}", ""]

    num_conv_roles = len(conversation_roles) or 3
    current_round = 0
    msgs_in_round = 0
    analyst_content = ""

    for msg in messages:
        if msg.msg_type != "completed":
            continue
        if msg.role not in conversation_roles:
            if "åˆ†æ" in msg.role and msg.msg_type == "completed":
                analyst_content = msg.content
            continue
        if msgs_in_round % num_conv_roles == 0:
            current_round += 1
            lines.append(f"\n### ç¬¬ {current_round} è½®\n")
        msgs_in_round += 1
        avatar = avatars.get(msg.role, "")
        lines.append(f"**{avatar} {msg.role}:**\n")
        lines.append(f"{msg.content}\n")

    if analyst_content:
        lines.append("\n---\n")
        lines.append("### åˆ†ææ€»ç»“\n")
        lines.append(analyst_content)

    return "\n".join(lines)


def render_messages(messages: list[ChatMessage]):
    """Render conversation messages (excludes analyst output)."""
    avatars = get_role_avatars()
    for msg in messages:
        if msg.msg_type == "started":
            continue
        if "åˆ†æ" in msg.role:
            continue
        avatar = avatars.get(msg.role, "ğŸ’¬")
        if msg.role == "system":
            st.caption(msg.content)
        else:
            with st.chat_message(msg.role, avatar=avatar):
                st.markdown(f"**{msg.role}**")
                st.write(msg.content)


def render_analyst(messages: list[ChatMessage]):
    """Render the analyst output in a separate expander."""
    for msg in messages:
        if "åˆ†æ" in msg.role and msg.msg_type == "completed":
            with st.expander("ğŸ“Š ç¾¤ä½“äº’åŠ¨åˆ†æ", expanded=False):
                st.markdown(msg.content)
            return


def extract_conversation_text(messages: list[ChatMessage]) -> str:
    """Extract completed conversation messages as plain text."""
    parts = []
    for msg in messages:
        if msg.msg_type == "completed" and msg.role != "system":
            parts.append(f"[{msg.role}]: {msg.content}")
    return "\n\n".join(parts)


# ---------------------------------------------------------------------------
# Multi-style simulation runner (synchronous, called from background thread)
# ---------------------------------------------------------------------------

def run_multi_style_simulation(
    topic: str,
    num_rounds: int,
    selected_style_ids: list[str],
    style_stores: dict[str, ChatMessageStore],
    progress_callback,
    config: dict,
):
    """Run simulation for each selected style sequentially.

    Populates style_stores with messages for each style, then runs comparison.
    """
    repo = RoleRepository()
    base_db = repo.load_roles()
    total_steps = len(selected_style_ids) + (1 if len(selected_style_ids) > 1 else 0)
    style_conversations: dict[str, str] = {}

    # Bind to the same OpenAI-compatible endpoint/model shown in the sidebar.
    # Without this, CrewAI may fall back to a default provider/config and hang
    # before emitting any task events (UI then shows "å¯åŠ¨è¶…æ—¶").
    try:
        llm = create_primary_llm()
    except Exception as e:
        raise RuntimeError(f"LLM åˆå§‹åŒ–å¤±è´¥: {type(e).__name__}: {e}") from e

    stream_enabled = bool(config.get("stream", True))

    for idx, style_id in enumerate(selected_style_ids):
        style = LEADERSHIP_STYLES[style_id]
        store = style_stores[style_id]

        # Check if cancelled before starting
        if store.cancelled:
            logger.info(f"Simulation cancelled before starting {style.style_name}")
            break

        try:
            styled_db = apply_style_to_roles(base_db, style)
            builder = CrewBuilder(styled_db, config, llm=llm)
            RUNTIME_STATE.set_progress(
                live=f"æ„å»ºä»»åŠ¡ä¸è§’è‰²: {style.style_name}",
                last_update=str(time.time()),
            )
            crew = builder.build_crew(topic, num_rounds)
            RUNTIME_STATE.active_store = store
            RUNTIME_STATE.set_current_prefix(style_id)
            progress_callback(idx, total_steps, style.style_name)
            logger.info(f"Starting simulation for style: {style.style_name}")
            logger.info(f"Topic: {topic}, Rounds: {num_rounds}")

            # Run crew with timeout monitoring
            start_time = time.time()
            if stream_enabled:
                streaming = crew.kickoff()
                if isinstance(streaming, CrewStreamingOutput):
                    buffers: dict[str, str] = {}
                    for chunk in streaming:
                        if store.cancelled:
                            break
                        if chunk.chunk_type != StreamChunkType.TEXT:
                            # Tool call chunks can be shown in terminal logs; keep UI clean for now.
                            continue
                        if not chunk.content:
                            continue
                        msg_key = f"{style_id}:{chunk.task_id}" if chunk.task_id else f"{style_id}:{chunk.agent_id}:{chunk.task_index}"
                        prev = buffers.get(msg_key, "")
                        new = prev + chunk.content
                        buffers[msg_key] = new
                        store.upsert(key=msg_key, role=chunk.agent_role or "assistant", content=new, msg_type="stream")
                        RUNTIME_STATE.set_progress(last_update=str(time.time()))
                    # Ensure we can access the final result (may raise if cancelled mid-stream).
                    try:
                        _ = streaming.result
                    except Exception:
                        pass
                else:
                    # Fallback: non-streaming output
                    crew.kickoff()
            else:
                crew.kickoff()
            elapsed = time.time() - start_time
            store.finalize_streaming()

            logger.info(f"Simulation completed for {style.style_name} in {elapsed:.1f}s")
            store.mark_done()
        except Exception as e:
            error_msg = f"{type(e).__name__}: {str(e)}"
            logger.error(f"Simulation failed for {style.style_name}: {error_msg}")

            store.mark_error(error_msg)
        finally:
            RUNTIME_STATE.active_store = None
            RUNTIME_STATE.set_current_prefix("")

        style_conversations[style.style_name] = extract_conversation_text(
            store.get_all()
        )

    # Run cross-style comparison if multiple styles selected
    if len(selected_style_ids) > 1:
        comparison_store = style_stores.get("__comparison__")
        if comparison_store is not None:
            try:
                RUNTIME_STATE.active_store = comparison_store
                RUNTIME_STATE.set_current_prefix("__comparison__")
                progress_callback(
                    len(selected_style_ids), total_steps, "è·¨é£æ ¼å¯¹æ¯”åˆ†æ"
                )
                logger.info("Starting cross-style comparison analysis")
                RUNTIME_STATE.set_progress(
                    live="æ„å»ºè·¨é£æ ¼å¯¹æ¯”åˆ†æä»»åŠ¡",
                    last_update=str(time.time()),
                )
                comparison_crew = build_comparison_crew(topic, style_conversations, llm=llm, stream=stream_enabled)

                start_time = time.time()
                if stream_enabled:
                    streaming = comparison_crew.kickoff()
                    if isinstance(streaming, CrewStreamingOutput):
                        buffers: dict[str, str] = {}
                        for chunk in streaming:
                            if comparison_store.cancelled:
                                break
                            if chunk.chunk_type != StreamChunkType.TEXT:
                                continue
                            if not chunk.content:
                                continue
                            msg_key = (
                                f"__comparison__:{chunk.task_id}"
                                if chunk.task_id
                                else f"__comparison__:{chunk.agent_id}:{chunk.task_index}"
                            )
                            prev = buffers.get(msg_key, "")
                            new = prev + chunk.content
                            buffers[msg_key] = new
                            comparison_store.upsert(
                                key=msg_key,
                                role=chunk.agent_role or "è·¨é£æ ¼å¯¹æ¯”åˆ†æå¸ˆ",
                                content=new,
                                msg_type="stream",
                            )
                            RUNTIME_STATE.set_progress(last_update=str(time.time()))
                        try:
                            _ = streaming.result
                        except Exception:
                            pass
                    else:
                        comparison_crew.kickoff()
                else:
                    comparison_crew.kickoff()
                elapsed = time.time() - start_time
                comparison_store.finalize_streaming()

                logger.info(f"Comparison analysis completed in {elapsed:.1f}s")
                comparison_store.mark_done()
            except Exception as e:
                error_msg = f"{type(e).__name__}: {str(e)}"
                logger.error(f"Comparison analysis failed: {error_msg}")

                comparison_store.mark_error(error_msg)
            finally:
                RUNTIME_STATE.active_store = None
                RUNTIME_STATE.set_current_prefix("")


# ---------------------------------------------------------------------------
# Background thread wrapper for multi-style simulation
# ---------------------------------------------------------------------------

def _run_in_thread(topic, num_rounds, selected_style_ids, style_stores, config):
    """Background thread entry point for multi-style simulation."""

    RUNTIME_STATE.set_llm(
        status="idle",
        call_count=0,
        completed_count=0,
        failed_count=0,
        agent_role="",
        model="",
        call_started_at="",
    )

    def progress_callback(step, total, label):
        RUNTIME_STATE.set_progress(
            step=str(step + 1),
            total=str(total),
            label=label,
            last_update=str(time.time()),
        )

    try:
        run_multi_style_simulation(
            topic, num_rounds, selected_style_ids, style_stores, progress_callback, config
        )
    except Exception as e:
        logger.exception("Simulation thread crashed before completion")
        error_msg = f"è¿è¡Œçº¿ç¨‹å¼‚å¸¸: {type(e).__name__}: {str(e)}"
        RUNTIME_STATE.set_progress(live=error_msg, last_update=str(time.time()))
        for store in style_stores.values():
            if not store.done:
                store.mark_error(error_msg)
    finally:
        RUNTIME_STATE.set_progress(done="true", last_update=str(time.time()))


# ---------------------------------------------------------------------------
# Streamlit UI
# ---------------------------------------------------------------------------

def main():
    st.set_page_config(
        page_title="Agent äººç¾¤æ¨¡æ‹Ÿç ”ç©¶",
        page_icon="ğŸ”¬",
        layout="wide",
    )

    st.title("ğŸ”¬ Agent äººç¾¤æ¨¡æ‹Ÿç ”ç©¶")
    st.caption("åŸºäº LLM å¤šæ™ºèƒ½ä½“çš„ç¾¤ä½“è¡Œä¸ºæ¨¡æ‹Ÿ â€” é¢†å¯¼é£æ ¼å¯¹æ¯”åˆ†æ")

    # -- Sidebar --
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        topic = st.text_input(
            "ä¼šè®®è¯é¢˜",
            value="é¡¹ç›®å»¶æœŸäº†ï¼Œè°æ¥èƒŒé”…ï¼Ÿ",
            help="è¾“å…¥ä¸€ä¸ªæ¨¡æ‹Ÿåœºæ™¯è¯é¢˜",
        )
        num_rounds = st.slider(
            "å¯¹è¯è½®æ•°", min_value=1, max_value=10, value=3,
            help="æ¯è½®è§’è‰²å„å‘è¨€ä¸€æ¬¡ï¼Œè½®æ•°è¶Šå¤šå‰§æƒ…è¶Šä¸°å¯Œ",
        )

        with st.expander("ğŸ”§ é«˜çº§è®¾ç½®", expanded=False):
            stream_output = st.checkbox(
                "æµå¼è¾“å‡ºï¼ˆæ¨èï¼‰",
                value=True,
                help="å¼€å¯åï¼ŒLLM çš„è¾“å‡ºä¼šåœ¨å‰ç«¯é€å­—æ˜¾ç¤ºï¼Œç­‰å¾…ä½“éªŒæ›´å¥½ï¼›å…³é—­ååªåœ¨å®Œæˆæ—¶ä¸€æ¬¡æ€§æ˜¾ç¤ºã€‚",
            )
            agent_timeout = st.slider(
                "Agentè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰",
                min_value=30,
                max_value=300,
                value=120,
                step=30,
                help="å•ä¸ªAgentçš„æœ€å¤§æ‰§è¡Œæ—¶é—´ï¼Œè¶…æ—¶åä¼šç»ˆæ­¢",
            )
            max_iterations = st.slider(
                "æœ€å¤§è¿­ä»£æ¬¡æ•°",
                min_value=1,
                max_value=10,
                value=5,
                help="é˜²æ­¢Agenté™·å…¥æ— é™å¾ªç¯",
            )
            context_window = st.slider(
                "ä¸Šä¸‹æ–‡çª—å£ï¼ˆä»»åŠ¡æ•°ï¼‰",
                min_value=2,
                max_value=12,
                value=4,
                step=2,
                help="æ¯ä¸ªAgentèƒ½çœ‹åˆ°çš„å†å²ä»»åŠ¡æ•°é‡ï¼Œè¶Šå¤§æ¶ˆè€—è¶Šå¤štoken",
            )

        st.divider()

        # Model status display
        st.subheader("æ¨¡å‹é…ç½®")
        primary_model = os.getenv("OPENAI_MODEL_NAME", "")
        primary_base_url = os.getenv("OPENAI_BASE_URL", "")
        primary_api_key = os.getenv("OPENAI_API_KEY", "")

        st.caption(f"æ¥å£: `{primary_base_url or 'æœªé…ç½®'}`")
        st.caption(f"æ¨¡å‹: **{primary_model or 'æœªé…ç½®'}**")
        if not primary_api_key or not primary_model:
            st.warning("âš ï¸ æ— å¯ç”¨æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ .env é…ç½®")

        st.divider()
        st.subheader("é¢†å¯¼é£æ ¼é€‰æ‹©")
        style_options = {
            sid: s.style_name for sid, s in LEADERSHIP_STYLES.items()
        }
        selected_styles = st.multiselect(
            "é€‰æ‹©è¦å¯¹æ¯”çš„é¢†å¯¼é£æ ¼ï¼ˆè‡³å°‘1ä¸ªï¼‰",
            options=list(style_options.keys()),
            default=list(style_options.keys()),
            format_func=lambda sid: f"{style_options[sid]}",
        )

        # Show style descriptions
        for sid in selected_styles:
            style = LEADERSHIP_STYLES[sid]
            st.caption(f"**{style.style_name}**: {style.description}")

        start_btn = st.button(
            "ğŸš€ å¼€å§‹æ¨¡æ‹Ÿ",
            type="primary",
            use_container_width=True,
            disabled=len(selected_styles) == 0,
        )

        st.divider()
        st.subheader("è§’è‰²ä»‹ç»")
        avatars = get_role_avatars()
        for role_name, avatar in avatars.items():
            if role_name not in ("system", "è·¨é£æ ¼å¯¹æ¯”åˆ†æå¸ˆ"):
                st.write(f"{avatar} **{role_name}**")

    # -- Initialize session state --
    if "style_stores" not in st.session_state:
        st.session_state.style_stores = {}
    if "running" not in st.session_state:
        st.session_state.running = False
    if "sim_topic" not in st.session_state:
        st.session_state.sim_topic = ""
    if "sim_num_rounds" not in st.session_state:
        st.session_state.sim_num_rounds = 3
    if "selected_style_ids" not in st.session_state:
        st.session_state.selected_style_ids = []
    if "agent_timeout" not in st.session_state:
        st.session_state.agent_timeout = 120
    if "max_iterations" not in st.session_state:
        st.session_state.max_iterations = 5
    if "context_window" not in st.session_state:
        st.session_state.context_window = 4
    if "stream_output" not in st.session_state:
        st.session_state.stream_output = True
    if "worker_thread" not in st.session_state:
        st.session_state.worker_thread = None

    # -- Handle start button --
    if start_btn and not st.session_state.running and selected_styles:
        # Validate API endpoint before starting
        is_valid, error_msg = validate_api_endpoint()
        if not is_valid:
            st.error(error_msg)
            st.info("ğŸ’¡ æç¤ºï¼šå¦‚æœä½¿ç”¨æœ¬åœ°ä»£ç†ï¼Œè¯·ç¡®ä¿ä»£ç†æœåŠ¡æ­£åœ¨è¿è¡Œ")
            st.stop()

        stores: dict[str, ChatMessageStore] = {}
        for sid in selected_styles:
            stores[sid] = ChatMessageStore()
        if len(selected_styles) > 1:
            stores["__comparison__"] = ChatMessageStore()

        st.session_state.style_stores = stores
        st.session_state.running = True
        st.session_state.sim_topic = topic
        st.session_state.sim_num_rounds = num_rounds
        st.session_state.selected_style_ids = list(selected_styles)
        st.session_state.agent_timeout = agent_timeout
        st.session_state.max_iterations = max_iterations
        st.session_state.context_window = context_window
        st.session_state.stream_output = stream_output
        st.session_state.sim_started_at = time.time()

        total_steps = len(selected_styles) + (1 if len(selected_styles) > 1 else 0)
        RUNTIME_STATE.set_progress(
            step="0",
            total=str(max(total_steps, 1)),
            label="åˆå§‹åŒ–ä»»åŠ¡",
            live="ç­‰å¾…ç¬¬ä¸€ä¸ªè§’è‰²å¼€å§‹",
            last_update=str(time.time()),
        )
        RUNTIME_STATE.set_llm(
            status="idle",
            call_count=0,
            completed_count=0,
            failed_count=0,
            agent_role="",
            model="",
            call_started_at="",
        )

        config = {
            "agent_timeout": agent_timeout,
            "max_iterations": max_iterations,
            "context_window": context_window,
            "stream": stream_output,
        }

        thread = threading.Thread(
            target=_run_in_thread,
            args=(topic, num_rounds, list(selected_styles), stores, config),
            daemon=True,
        )
        thread.start()
        st.session_state.worker_thread = thread

    # -- Main area: render based on state --
    style_stores = st.session_state.style_stores
    style_ids = st.session_state.selected_style_ids

    if st.session_state.running and style_stores:
        # Check if all stores are done
        all_done = all(
            store.done for sid, store in style_stores.items()
            if sid != "__comparison__"
        )
        comparison_store = style_stores.get("__comparison__")
        comparison_done = comparison_store.done if comparison_store else True

        if not (all_done and comparison_done):
            _progress_info = RUNTIME_STATE.snapshot_progress()
            _llm_call_info = RUNTIME_STATE.snapshot_llm()
            label = _progress_info.get("label", "å‡†å¤‡ä¸­...")
            step = int(_progress_info.get("step", "0") or "0")
            total = max(int(_progress_info.get("total", "1") or "1"), 1)
            live = _progress_info.get("live", "ç­‰å¾…ä»»åŠ¡å¯åŠ¨")
            last_update = float(_progress_info.get("last_update", "0") or "0")
            started_at = st.session_state.get("sim_started_at", time.time())
            elapsed = int(time.time() - started_at)
            idle_seconds = int(time.time() - last_update) if last_update > 0 else elapsed
            progress_ratio = min(max(step / total, 0.0), 1.0)
            worker = st.session_state.get("worker_thread")

            # Guardrail: if worker thread has exited but stores are not done, fail fast with diagnostics.
            if worker is not None and not worker.is_alive():
                fail_msg = "åå°æ‰§è¡Œçº¿ç¨‹å·²é€€å‡ºï¼Œä»»åŠ¡æœªå®Œæˆã€‚è¯·é‡è¯•ï¼›è‹¥é‡å¤å‡ºç°ï¼Œè¯·æ£€æŸ¥ç»ˆç«¯æ—¥å¿—ã€‚"
                for store in style_stores.values():
                    if not store.done:
                        store.mark_error(fail_msg)
                st.session_state.running = False
                st.error(f"âŒ {fail_msg}")
                st.rerun()

            # Guardrail: no update for too long while still at initial phase usually means startup failure.
            if step == 0 and idle_seconds > 45:
                timeout_msg = f"å¯åŠ¨è¶…æ—¶ï¼š{idle_seconds}s å†…æœªæ”¶åˆ°ä»»åŠ¡äº‹ä»¶ã€‚è¯·æ£€æŸ¥æ¨¡å‹æ¥å£ä¸æ—¥å¿—ã€‚"
                for store in style_stores.values():
                    if not store.done:
                        store.mark_error(timeout_msg)
                st.session_state.running = False
                st.error(f"âŒ {timeout_msg}")
                st.rerun()

            col1, col2 = st.columns([3, 1])
            with col1:
                llm_status = _llm_call_info.get("status", "idle")
                call_count = int(_llm_call_info.get("call_count", 0))
                completed_count = int(_llm_call_info.get("completed_count", 0))
                failed_count = int(_llm_call_info.get("failed_count", 0))

                if llm_status == "sending":
                    call_started = float(_llm_call_info.get("call_started_at", 0) or 0)
                    waiting_sec = int(time.time() - call_started) if call_started > 0 else 0
                    st.warning(f"ğŸ“¡ æ¨¡æ‹Ÿè¿›è¡Œä¸­ â€” {label}ã€€|ã€€æ­£åœ¨ç­‰å¾… LLM å“åº”... ({waiting_sec}s)")
                elif llm_status == "failed":
                    st.error(f"âš ï¸ æ¨¡æ‹Ÿè¿›è¡Œä¸­ â€” {label}ã€€|ã€€ä¸Šæ¬¡è¯·æ±‚å¤±è´¥ï¼Œé‡è¯•ä¸­...")
                else:
                    st.info(f"ğŸ”„ æ¨¡æ‹Ÿè¿›è¡Œä¸­ â€” {label}")

                st.progress(progress_ratio, text=f"é˜¶æ®µè¿›åº¦: {step}/{total}")
                st.caption(
                    f"å·²è¿è¡Œ: {elapsed}s | LLM è°ƒç”¨: {completed_count}/{call_count} å®Œæˆ"
                    + (f" Â· {failed_count} å¤±è´¥" if failed_count else "")
                    + f" | {live}"
                )
            with col2:
                if st.button("ğŸ›‘ å–æ¶ˆæ¨¡æ‹Ÿ", type="secondary", use_container_width=True):
                    # Mark all stores as cancelled
                    for store in style_stores.values():
                        store.mark_cancelled()
                    st.session_state.running = False
                    st.warning("âš ï¸ æ¨¡æ‹Ÿå·²å–æ¶ˆ")
                    st.rerun()

            # Stream partial outputs while running (tabs update on each rerun).
            _render_results_tabs(style_stores, style_ids)
            time.sleep(1.0)
            st.rerun()

        # All done â€” stop polling
        st.session_state.running = False

        # Check if any were cancelled
        any_cancelled = any(store.cancelled for store in style_stores.values())
        if any_cancelled:
            st.warning("âš ï¸ æ¨¡æ‹Ÿå·²è¢«ç”¨æˆ·å–æ¶ˆ")
        else:
            st.success("âœ… æ‰€æœ‰é£æ ¼æ¨¡æ‹Ÿå®Œæˆï¼")

    if style_stores and not st.session_state.running:
        _render_results_tabs(style_stores, style_ids)

    elif not style_stores:
        st.info("ğŸ‘ˆ åœ¨å·¦ä¾§é€‰æ‹©é¢†å¯¼é£æ ¼å¹¶è¾“å…¥è¯é¢˜ï¼Œç‚¹å‡»ã€Œå¼€å§‹æ¨¡æ‹Ÿã€")


main()
